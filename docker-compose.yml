services:
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      CLUSTER_ID: '${KAFKA_CLUSTER_ID}'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    env_file:
      - .env

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    env_file:
      - .env

  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3307:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init:/docker-entrypoint-initdb.d
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "mysqladmin" ,"ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      timeout: 20s
      retries: 10
      start_period: 10s

  db-importer:
    build: .
    container_name: db-importer
    command: python scripts/import_to_db.py
    environment:
      - PYTHONPATH=/app
    depends_on:
      mysql:
        condition: service_healthy
    env_file:
      - .env

  # --- THIS IS THE ONLY WEB SERVER ---
  backend:
    build: .
    container_name: backend
    command: gunicorn --worker-class eventlet --workers 1 --bind 0.0.0.0:5000 backend.api.app:app
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
    depends_on:
      db-importer:
        condition: service_completed_successfully
      kafka:
        condition: service_started
    restart: on-failure

  db-streamer:
    build: .
    container_name: db-streamer
    command: python -u backend/data_pipeline/db_streamer.py
    environment:
      - PYTHONPATH=/app
    depends_on:
      db-importer:
        condition: service_completed_successfully
      kafka:
        condition: service_started
    env_file:
      - .env
    restart: on-failure

  dvr-consumer:
    build: .
    container_name: dvr-consumer 
    command: python -u backend/data_pipeline/dvr_consumer.py 
    environment:
      - PYTHONPATH=/app
    depends_on:
      - kafka
    env_file:
      - .env
    restart: on-failure

  validated-data-consumer:
    build: .
    container_name: validated-data-consumer
    command: python -u backend/data_pipeline/validated_data_consumer.py
    environment:
      - PYTHONPATH=/app
    depends_on:
      - kafka
      - influxdb
    env_file:
      - .env
    restart: on-failure

  rtm-consumer:
    build: .
    container_name: rtm-consumer
    command: python -u backend/data_pipeline/rtm_consumer.py
    environment:
      - PYTHONPATH=/app
    depends_on:
      - kafka
    env_file:
      - .env
    restart: on-failure

  influx-writer:
    build: .
    container_name: influx-writer
    command: python -u backend/data_pipeline/kafka_consumer_influx.py
    environment:
      - PYTHONPATH=/app
    depends_on:
      - kafka
      - influxdb
    env_file:
      - .env
    restart: on-failure

volumes:
  influxdb_data:
  mysql_data: