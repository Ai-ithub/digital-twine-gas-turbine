### گزارش کار: پیاده‌سازی مدل LSTM برای پیش‌بینی مصرف انرژی با استفاده از داده‌های سری زمانی

#### **خلاصه**
در این پروژه، یک مدل شبکه عصبی بازگشتی (LSTM) پیاده‌سازی شده است که به منظور پیش‌بینی مصرف انرژی یک فشاردهی صنعتی (Power Consumption) از داده‌های سری زمانی استفاده می‌کند. ابتدا داده‌ها پاک‌سازی و پیش‌پردازش شدند، سپس با استفاده از فیلتر کالمن نویز داده‌ها کاهش یافت. در مرحله بعد، داده‌ها به دنباله‌های زمانی تبدیل شدند و مدل LSTM برای آموزش روی این داده‌ها استفاده شد. در پایان، مدل با استفاده از GPU آموزش دید.

---

### **1. مقدمه**
هدف از این پروژه پیش‌بینی مقدار مصرف انرژی (Power Consumption) یک فشاردهی صنعتی است. داده‌های ورودی شامل پارامترهای مختلفی مانند فشار ورودی (Pressure_In)، دما ورودی (Temperature_In)، نرخ جریان (Flow_Rate)، کارایی (Efficiency)، و ارتعاش (Vibration) هستند. این پروژه شامل مراحل زیر است:

1. **خواندن و پیش‌پردازش داده‌ها**
2. **استفاده از فیلتر کالمن برای کاهش نویز**
3. **تولید دنباله‌های زمانی**
4. **ساخت مدل LSTM**
5. **آموزش مدل با استفاده از GPU**
6. **ارزیابی عملکرد مدل**

---

### **2. مراحل پیاده‌سازی**

#### **مرحله 1: خواندن داده‌ها**
داده‌ها از یک فایل CSV با نام `balanced_compressor_time_series_data.csv` خوانده شدند. ستون "Time" به عنوان زمان ثبت داده‌ها در نظر گرفته شد و به فرمت تاریخ و ساعت تبدیل شد. این ستون به عنوان اندیس داده‌ها تنظیم شد.

```python
data["Datetime"] = pd.to_datetime(data["Time"], unit='s')
data.set_index("Datetime", inplace=True)
data.drop("Time", axis=1, inplace=True)
```

---

#### **مرحله 2: پیش‌پردازش داده‌ها**
- **معیاری‌سازی داده‌ها:** ویژگی‌های ورودی (`features`) شامل "Pressure_In"، "Temperature_In"، "Flow_Rate"، "Efficiency"، و "Vibration" بودند. این داده‌ها با استفاده از `StandardScaler` معیاری‌سازی شدند.
- **کاهش نویز با فیلتر کالمن:** برای کاهش نویز موجود در داده‌های "Vibration"، از یک فیلتر کالمن استفاده شد.

```python
kf = KalmanFilter(process_variance=1e-5, measurement_variance=1e-5, estimated_measurement_variance=1e-5)
data[target] = [kf.update(v) for v in data[target]]
```

---

#### **مرحله 3: تولید دنباله‌های زمانی**
برای آماده‌سازی داده‌ها برای مدل LSTM، داده‌ها به دنباله‌های زمانی با طول 3600 ثانیه (1 ساعت) تبدیل شدند. هدف پیش‌بینی مقدار مصرف انرژی در 60 ثانیه آینده بود.

```python
def create_sequences(data, features, target, seq_length):
    X = np.lib.stride_tricks.sliding_window_view(data[features].values, (seq_length, len(features))).squeeze(axis=1)
    y = data[target].values[seq_length:]
    X = X[:len(y)]
    return X, y
```

---

#### **مرحله 4: تقسیم داده‌ها به مجموعه‌های آموزش و تست**
داده‌ها به دو بخش آموزش (80%) و تست (20%) تقسیم شدند. برای بهینه‌سازی آموزش مدل، از کلاس `Dataset` و `DataLoader` در PyTorch استفاده شد.

```python
train_dataset = TimeSeriesDataset(X_train, y_train)
test_dataset = TimeSeriesDataset(X_test, y_test)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```

---

#### **مرحله 5: ساخت مدل LSTM**
مدل LSTM شامل یک لایه LSTM و یک لایه خطی است. ورودی مدل شامل 5 ویژگی است و خروجی آن مقدار مصرف انرژی را پیش‌بینی می‌کند.

```python
class LSTMModel(nn.Module):
    def _init_(self, input_size, hidden_layer_size, output_size):
        super(LSTMModel, self)._init_()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)
        self.linear = nn.Linear(hidden_layer_size, output_size)
    def forward(self, x):
        lstm_out, (h_n, c_n) = self.lstm(x)
        predictions = self.linear(lstm_out[:, -1])  # Use the last output of the LSTM
        return predictions
```

---

#### **مرحله 6: آموزش مدل با استفاده از GPU**
برای افزایش سرعت آموزش مدل، از GPU استفاده شد. مدل و داده‌ها به حافظه GPU منتقل شدند و آموزش مدل با استفاده از تابع `MSELoss` و بهینه‌ساز `Adam` انجام شد.

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:
        for X_batch, y_batch in pbar:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            y_pred = model(X_batch)
            loss = criterion(y_pred, y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
            pbar.set_postfix({'Loss': train_loss / (pbar.n + 1)})
```

---

### **3. نتایج**
مدل LSTM با موفقیت روی داده‌های آموزشی آموخته شد و توانست خطای آموزشی را کاهش دهد. استفاده از GPU به طور قابل توجهی سرعت آموزش مدل را افزایش داد.

---

### **4. نتیجه‌گیری**
در این پروژه، یک مدل LSTM برای پیش‌بینی مصرف انرژی یک فشاردهی صنعتی پیاده‌سازی شد. استفاده از فیلتر کالمن برای کاهش نویز و استفاده از GPU برای سرعت‌بخشی به آموزش مدل، نقاط قوت این پروژه بودند. در آینده، می‌توان از روش‌های دیگر مثل Attention Mechanism یا Transformer برای بهبود عملکرد مدل استفاده کرد.