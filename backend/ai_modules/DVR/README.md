# ğŸ“Œ Data Validation & Reconciliation (DVR)

## ğŸ¯ Objective
Ensure the reliability of sensor data by detecting and correcting faulty measurements before they affect downstream AI modules (like PdM or RTO).


## ğŸ§  Algorithms Used

| Algorithm                     | Purpose                                                                 |
|-------------------------------|-------------------------------------------------------------------------|
| âœ… Rule-Based Checks           | Detect physically invalid data (e.g., negative flow, extreme temperature) |
| âœ… PCA (Principal Component Analysis) | Identify multivariate anomalies due to correlated sensor faults         |
| â³ WLS (Weighted Least Squares)      | Reconstruct missing or noisy values using sensor relationships         |
| â³ Bayesian Inference          | Probabilistic estimation of true sensor values with confidence intervals |


## ğŸ“‹ Tasks To-Do

- [x] Implement domain-specific rules (e.g., acceptable ranges and rate-of-change)
- [x] Apply PCA-based anomaly detection
- [ ] Implement WLS for data correction
- [ ] Apply Bayesian modeling (optional but useful)
- [ ] Visualize raw vs cleaned data, and log anomalies


## ğŸ“¦ Expected Output

- Cleaned sensor dataset
- Anomaly labels (pr row or column)
- Corrected values (when possible)
- Visualization of error regions, outlier sensors, and reconstructed data


## ğŸ’¡ Why It Matters

Inaccurate or missing sensor data can lead to:

- Wrong predictions in PdM models
- Dangerous optimization recommendations
- Unreliable alert systems

DVR improves **data trust**, making predictions and decisions **more robust and safe**.

